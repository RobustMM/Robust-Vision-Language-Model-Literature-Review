# Robust-Vision-Language-Model-Literature-Review

## Vision-Language Foundation Model
| Year | Venue | Title | Institute | Paper Link | Code Link |
| :---:| :---: | :---: | :---: | :---: | :---: | 
| 2023 | Arxiv | BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models | Salesforce Research | [Link](https://arxiv.org/abs/2301.12597) | [Link](https://github.com/salesforce/LAVIS/tree/main/projects/blip2)
| 2022 | ICML  | BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation | Salesforce Research | [Link](https://proceedings.mlr.press/v162/li22n/li22n.pdf) | [Link](https://github.com/salesforce/BLIP)
| 2021 | ICML  | Learning Transferable Visual Models From Natural Language Supervision | OpenAI | [Link](https://proceedings.mlr.press/v139/radford21a/radford21a.pdf) | [Link](https://github.com/OpenAI/CLIP)


## Vision-Language Model - Domain Generalization
| Year | Venue | Title | Institute | Paper Link | Code Link |
| :---:| :---: | :---: | :---: | :---: | :---: |

## Vision-Language Model - Few Shot Learning
| Year | Venue | Title | Institute | Paper Link | Code Link |
| :---:| :---: | :---: | :---: | :---: | :---: |

## Vision-Language Model - Other Downstream
| Year | Venue | Title | Institute | Paper Link | Code Link |
| :---:| :---: | :---: | :---: | :---: | :---: |
